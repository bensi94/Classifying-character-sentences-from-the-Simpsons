[GOOD SHIT LINKUR!](https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f)

[Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf):

*We report on a series of experiments with
convolutional neural networks (CNN)
trained on top of pre-trained word vectors
for sentence-level classification tasks.
We show that a simple CNN with little
hyperparameter tuning and static vectors
achieves excellent results on multiple
benchmarks. Learning task-specific
vectors through fine-tuning offers further
gains in performance. We additionally
propose a simple modification to the architecture
to allow for the use of both
task-specific and static vectors. The CNN
models discussed herein improve upon the
state of the art on 4 out of 7 tasks, which
include sentiment analysis and question
classification.*

[Machine Learning in Automated Text Categorization](http://delivery.acm.org/10.1145/510000/505283/p1-sebastiani.pdf?ip=130.208.240.8&id=505283&acc=ACTIVE%20SERVICE&key=2F5186C3D8457522%2E5BB55B46228E0BA5%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1538698507_e7f792fc12396aa9d5e72da2b7bb627f):

*The automated categorization (or classification) of texts into predefined categories has
witnessed a booming interest in the last 10 years, due to the increased availability of
documents in digital form and the ensuing need to organize them. In the research
community the dominant approach to this problem is based on machine learning
techniques: a general inductive process automatically builds a classifier by learning,
from a set of preclassified documents, the characteristics of the categories. The
advantages of this approach over the knowledge engineering approach (consisting in
the manual definition of a classifier by domain experts) are a very good effectiveness,
considerable savings in terms of expert labor power, and straightforward portability to
different domains. This survey discusses the main approaches to text categorization
that fall within the machine learning paradigm. We will discuss in detail issues
pertaining to three different problems, namely, document representation, classifier
construction, and classifier evaluation.*

[Support Vector Machine Active Learning
with Applications to Text Classification](http://www.jmlr.org/papers/volume2/tong01a/tong01a.pdf):

*Support vector machines have met with significant success in numerous real-world learning
tasks. However, like most machine learning algorithms, they are generally applied using
a randomly selected training set classified in advance. In many settings, we also have the
option ofusing pool-based active learning. Instead ofusing a randomly selected training
set, the learner has access to a pool ofunlabeled instances and can request the labels for
some number of them. We introduce a new algorithm for performing active learning with
support vector machines, i.e., an algorithm for choosing which instances to request next.
We provide a theoretical motivation for the algorithm using the notion of a version space.
We present experimental results showing that employing our active learning method can
significantly reduce the need for labeled training instances in both the standard inductive
and transductive settings.*

[Personality Classification Based on Twitter Text
Using Naive Bayes, KNN and SVM] (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7436992):

*Abstractâ€”Personality is a fundamental basis of human
behavior. Personality affects the interaction and preferences of an
individual. People are required to take a personality test to find
out their personality. Social media is a place where users express
themselves to the world. Posts made by users of social media can
be analyzed to obtain their personal information. This experiment
uses text classification to predict personality based on text written
by Twitter users. The languages used are English and Indonesian.
Classification methods implemented are Naive Bayes, K-Nearest
Neighbors and Support Vector Machine. Testing results showed
Naive Bayes slightly outperformed the other methods.*
